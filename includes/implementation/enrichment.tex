For the early research conducted in this project, enrichment was analyzed using the ParTI software package developed by the Uri Alon group\mcite{hart2015inferring}. However as Figure \ref{fig:enrichmentExample} illustrates the concept of enrichment is simple, and as such an implementation was made in Python which is shown in Appendix \ref{app:enrichment_code}. It takes a matrix of precomputed distances between samples and archetypes $\matr{D}$ and a matrix of feature-values corresponding to the same samples, and returns a JSON object that contains enrichments for each feature near each archetype (example given in Appendix \ref{app:enrichment_code}). Standard errors are computed for each associated bin as $\mathrm{SD}/\sqrt{N}$ where $N$ is the number of samples. Since the number of samples is large the standard error goes to 0 and is therefore not shown on the enrichment plots in Figure \ref{fig:firstEnrichmentsQuestionnaireValues}.

Statistical significance of enrichments is computed for the null hypothesis that: \textit{any random permutation of bins will result in greater $R^2$ \textbf{and} slope values for a first order polynomial fitted to the bin values}. The significance level is set to $\alpha = 0.05$ and a Bonferroni multiple hypothesis correction is used\mcite{dunn1961multiple}. For enrichment of attributes and facets, of which there are collectively 780 which all stem from the SAPA dataset, enrichments are therefore only accepted if they have a $p-$value smaller than $\alpha/780$, since there are 780 hypotheses being tested. For BHVs of which there are 10 the threshold is $\alpha/10$.