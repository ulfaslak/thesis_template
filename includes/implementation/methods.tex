For most data-driven projects, the typical pipeline includes extraction of data from some source and cleaning and reformatting of that data; there is typically feature engineering involved, which is the process of designing higher-level features based on a raw or semi-raw extract of data. After that comes outlier detection and typically also some variable transformation in order to balance the scales and distributions of signals in the data. All of these steps are called preprocessing, but will often require more work than any other task in the pipeline, simply because the it constitutes a bottelneck to the quality of the scientific analysis, where errors made in the early, result in poor or, even worse, misleading results. Because of this, preprocessing must be carried out with the desired analysis in mind, and analysis must be conducted with awareness of the problems that might result from errors in preprocessing.

While this project mainly relies on personality data, for which the extraction pipeline is simple, a significant amount effort has been invested in development of a reusable pipeline to extract \textit{behavioral indicators} from the SensibleDTU experiment dataset (see. Section \ref{subsec:sensibleDTU}). This pipeline constitutes an alternative value proposition of this research project because it can readily be applied by other researchers within Sensible DTU to extract high-level indicators for various purposes.

In the following, it is explained how the pipeline is implemented and behavior- and personality data from the SensibleDTU experiment is extracted. Then follows a brief section that explains the preprocessing of personality data from the remaining three datasources: \textit{myPersonality}, \textit{SAPA} and \textit{MIDUS}. Finally technical details about the analysis are presented.